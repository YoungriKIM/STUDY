데이터 불균형 보정, 데이터 증폭에 쓰인 기법
1) EDA: Easy Data Augmentation
2) RandomOverSampler
3) SMOTE: synthetic minority over-sampling technique

==================================================================================================
1) EDA(Easy Data Augmentation)
네 가지의 기법
1.유의어로 교체(Synonym Replacement, SR):
    문장에서 랜덤으로 stop words가 아닌 n 개의 단어들을 선택해
    임의로 선택한 동의어들 중 하나로 교체(wordnet 사용)
2.랜덤 삽입(Random Insertion, RI):
    문장 내에서 stop word를 제외한 나머지 단어들 중에서,
    랜덤으로 선택한 단어의 동의어를 임의로 정해 동의어를 문장 내 임의의 자리에 넣는 것을 n번 반복
3.랜덤 교체(Random Swap, RS)
     무작위로 문장 내에서 두 단어를 선택하고 위치를 교체. 이것도 n번 반복
4.랜덤 삭제(Random Deletion, RD):
    확률 p를 통해 문장 내에 있는 각 단어들을 랜덤하게 삭제

모델이 데이터의 특성을 충분히 학습할 수 있는 크기의 dataset이라면 오히려 노이즈를 증가
데이터셋이 적고 불균형 할 때 증강 + 노이즈 추가(과적합 방지)의 효과
문장의 길이가 길 수록 노이즈 영향을 상대적으로 덜 받음

데이터셋의 크기 별로 논문에서 추천하는 파라미터
N_train(500) - alpha(0.05) - N_aug(16)
N_train(2000) - alpha(0.05) - N_aug(8)
N_train(5000) - alpha(0.1) - N_aug(4)
N_train(more) - alpha(0.1) - N_aug(4)

한국어 모듈: https://github.com/catSirup/KorEDA
wordnet 출처: KAIST Korean WordNet(KWN)[http://wordnet.kaist.ac.kr/]
서버 내 wordner 경로: /ntdev/youngri/2.INTENT/dataset_using/wordnet.pickle
- wordner[의미 어휘목록]:
    단어의 동의어집단, 의미 관계, 쓰임 등을 정리한 단어집
    예) 인간 - 인물, 사람, 인류

==================================================================================================
2) RandomOverSampler
http://glemaitre.github.io/imbalanced-learn/generated/imblearn.over_sampling.RandomOverSampler.html

소수 클래스의 데이터를 단순 복제해서 넣어 비율을 맞추는 기법
데이터의 숫자만 늘어나고 분포는 변하지 않음

==================================================================================================
3) SMOTE(synthetic minority over-sampling technique)
https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTE.html

임의의 소수 클래스 데이터와 인근 소수 클래스 사이에 새로운 데이터를 생성하는 기법
Synthetic = X+u(X(nn)-X)
*임의의 소수 클래스 X | *X의 이웃 X(nn) | *0~1사이의 균등분포 u
예) X: X(5, 1) / X(nn): X(2, 3) / u: 0.2 --> X': X(4.4, 1.4)

